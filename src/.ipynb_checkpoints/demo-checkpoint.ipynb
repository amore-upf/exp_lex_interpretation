{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message='source.*has changed')\n",
    "warnings.filterwarnings(\"ignore\", message=\"Couldn't retrieve source code*\")\n",
    "import numpy as np\n",
    "from pytorch_transformers import *\n",
    "from lstm_utils import *\n",
    "from bert_utils import *\n",
    "from processing_utils import *\n",
    "from modeling_utils import *\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'LSTM/biLSTM_tiedT.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ceb4b23da264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlanguage_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_emb_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_languagemodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/Research/programming/exp_lex_interpretation/src/processing_utils.py\u001b[0m in \u001b[0;36mload_languagemodel\u001b[0;34m(model_type, cuda)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mlanguage_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'LSTM/biLSTM_tiedT.pt'"
     ]
    }
   ],
   "source": [
    "# model_eval : biLSTM_tiedT, or BERT-large/BERT-base\n",
    "model_type = 'LSTM'\n",
    "\n",
    "language_model, word_emb_matrix, vocab = load_languagemodel(model_type, model_dir = '../LSTM/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently combining expectation and lexical according to combine function in modeling_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "context = ' Her new show airs tonight on Netflix '\n",
    "word = 'show'\n",
    "index_target = context.split().index(word) \n",
    "\n",
    "expectation_info, lexical_info, combined_info = get_expectation_and_lexical_probs(language_model, vocab, word_emb_matrix, context,\n",
    "                                      index_target, model_eval, cuda=False,\n",
    "                                      combination_types=[combination_type], \n",
    "                                      params=alpha_values,cosine=use_cosine)\n",
    "\n",
    "expectation_vector, expectation_probabilities = expectation_info\n",
    "lexical_vector, lexical_probabilities = lexical_info\n",
    "# combined_info is a dictionary s.t. each key is an alpha value and each value is the output for that value\n",
    "combined_vector, combined_probabilities = combined_info['avg'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity expectation - lexical:  0.2348260134458542\n",
      "Similarity expectation - combined:  0.8723912835121155\n",
      "Similarity lexical - combined:  0.6799999475479126\n"
     ]
    }
   ],
   "source": [
    "print('Similarity expectation - lexical: ', cosine_similarity(expectation_vector, lexical_vector))\n",
    "print('Similarity expectation - combined: ', cosine_similarity(expectation_vector, combined_vector))\n",
    "print('Similarity lexical - combined: ', cosine_similarity(combined_vector, lexical_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors expectation:  ['home', '<unk>', 'favourite', 'style', 'recipe', 'name', 'musical', 'version', 'work', 'love']\n",
      "Nearest neighbors lexical: ['show', 'shows', 'showed', 'showing', 'Show', 'exhibit', 'demonstrate', 'indicate', 'display', 'offer']\n",
      "Nearest neighbors combined: ['show', 'shows', 'series', 'film', 'play', 'showing', 'album', 'tour', 'programme', 'offer']\n"
     ]
    }
   ],
   "source": [
    "# returns top n neighbors; if with_scores: returns tuple of list of top n neighbors and their scores\n",
    "\n",
    "print('Nearest neighbors expectation: ', nearest_neighbours(expectation_vector, word_emb_matrix, vocab, n=10, \n",
    "                                                            with_scores=False, into_words = True, model_eval = model_eval, cosine_sim = use_cosine))\n",
    "\n",
    "print('Nearest neighbors lexical:', nearest_neighbours(lexical_vector, word_emb_matrix, vocab, n=10, \n",
    "                                                            with_scores=False, into_words = True, model_eval = model_eval, cosine_sim = use_cosine))\n",
    "      \n",
    "print('Nearest neighbors combined:', nearest_neighbours(combined_vector, word_emb_matrix, vocab, n=10, \n",
    "                                                            with_scores=False, into_words = True, model_eval = model_eval, cosine_sim = use_cosine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['home',\n",
       "  '<unk>',\n",
       "  'favourite',\n",
       "  'style',\n",
       "  'recipe',\n",
       "  'name',\n",
       "  'musical',\n",
       "  'version',\n",
       "  'work',\n",
       "  'love'],\n",
       " ['home',\n",
       "  '<unk>',\n",
       "  'favourite',\n",
       "  'style',\n",
       "  'recipe',\n",
       "  'name',\n",
       "  'musical',\n",
       "  'version',\n",
       "  'work',\n",
       "  'love'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns tuple of top n items with highest probability and top n neighbors (should be identical)\n",
    "\n",
    "# if with_scores: it returns the values as well (probabilities and similarity scores)\n",
    "# Note that probabilities are just the similarity scores after applying softmax \n",
    "\n",
    "with_scores = False\n",
    "\n",
    "get_top_predictions(expectation_probabilities , expectation_vector, model_eval, word_emb_matrix, vocab,\n",
    "                        with_scores=with_scores, n=10, cosine=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_predictions(lexical_probabilities , lexical_vector, model_eval, word_emb_matrix, vocab,\n",
    "                        with_scores=with_scores, n=10, cosine=False, print_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_predictions(combined_probabilities , combined_vector, model_eval, word_emb_matrix, vocab,\n",
    "                        with_scores=with_scores, n=10, cosine=False, print_out=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other interesting values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Probability of the word according to expectations', expectation_probabilities[word2idx(word, vocab, model_eval)])\n",
    "print('KL divergence between expectation and lexical info', stats.entropy(expectation_probabilities,qk = lexical_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['home',\n",
       " 'favourite',\n",
       " 'style',\n",
       " 'recipe',\n",
       " 'name',\n",
       " 'musical',\n",
       " 'version',\n",
       " 'work',\n",
       " 'love',\n",
       " 'music']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
